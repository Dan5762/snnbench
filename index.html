
<!-- index.html -->
<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="apple-touch-icon" sizes="57x57" href="images/apple-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="60x60" href="images/apple-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="72x72" href="images/apple-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="76x76" href="images/apple-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="114x114" href="images/apple-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="120x120" href="images/apple-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="144x144" href="images/apple-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="152x152" href="images/apple-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="images/apple-icon-180x180.png">
    <link rel="icon" type="image/png" sizes="192x192"  href="images/android-icon-192x192.png">
    <link rel="icon" type="image/png" sizes="32x32" href="images/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="96x96" href="images/favicon-96x96.png">
    <link rel="icon" type="image/png" sizes="16x16" href="images/favicon-16x16.png">
  
    <link rel="manifest" href="manifest.json">
  
    <meta name="msapplication-TileColor" content="#ffffff">
    <meta name="msapplication-TileImage" content="/ms-icon-144x144.png">
    <meta name="theme-color" content="#ffffff">

    <title>SNN Benchmarks</title>
    <meta name="description" content="Public Benchmarking for Spiking Neural Networks">
    <meta name="author" content="Daniel Long">
    <meta property="og:title" content="SNN Benchmarks">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://snnbench.com">
    <meta property="og:description" content="Public Benchmarking for Spiking Neural Networks">

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-YQ1SQVV1YL"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-YQ1SQVV1YL');
    </script>

    <link rel="stylesheet" type="text/css" href="styles.css">
  </head>
  <body>
    <header>
        <h1>Spiking Neural Network Benchmarks</h1>
        <nav>
            <ul>
                <li><a href="index.html">Home</a></li>
                <li><a href="about.html">About</a></li>
                <li><a href="contact.html">Contact</a></li>
            </ul>
        </nav>
    </header>
    <main>
      <a href="benchmarks/mnist.html">
        <section class="section">
            <h2>MNIST</h2>
            <p>The MNIST dataset is a large collection of handwritten digits, ranging from 0 to 9, commonly used for training and testing in the field of machine learning and computer vision. It contains 60,000 training images and 10,000 testing images, each of which is a 28x28 pixel grayscale image. MNIST is widely used as a benchmark dataset for algorithms on image recognition, serving as an introductory dataset for neural network and machine learning techniques.</p>
        </section>
      </a>
      <a href="benchmarks/google_speech_commands_v2.html">
        <section class="section">
            <h2>Google Speech Commands v2</h2>
            <p>The Google Speech Commands dataset is designed to support the training and evaluation of keyword spotting systems in limited-vocabulary speech recognition tasks. It is specifically built for on-device models where resource constraints are significant. The dataset consists of 105,829 one-second audio clips of 35 words spoken by thousands of different speakers, designed to activate or control devices. The dataset aims to help develop models that accurately detect specific spoken words while minimizing false triggers from background noise or unrelated speech.</p>
        </section>
      </a>
      <a href="benchmarks/spiking_heidelberg_digits.html">
        <section class="section">
            <h2>Spiking Heidelberg Digits</h2>
            <p>The Spiking Heidelberg Digits dataset consists two datasets for evaluating spiking neural networks: Heidelberg Digits (HD) and Speech Commands (SC). HD consists of high-quality recordings of spoken digits in English and German, designed for classification tasks. SC includes 1-second audio clips of single spoken words, mimicking real-world conditions for keyword spotting on mobile devices. Both datasets convert audio to spike-based data to facilitate standardized performance benchmarking of various spiking neural network architectures.</p>
        </section>
    </main>
  </body>
</html>